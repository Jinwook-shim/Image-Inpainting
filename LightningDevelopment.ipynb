{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.mask_generator import MaskGenerator\n",
    "from dataloaders.images_dataset import ImagesDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models.pconv_unet import PConvUNet\n",
    "from models.vgg16_extractor import VGG16Extractor\n",
    "\n",
    "from loss.loss_compute import LossCompute\n",
    "\n",
    "from utils.preprocessing import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH = 256, 256\n",
    "invert_mask = False\n",
    "mask_dir = \"../Repos/image-inpainting/dataset/irregular_mask/irregular_mask/disocclusion_img_mask/\"\n",
    "train_dir = \"../Repos/image-inpainting/dataset/train_0\"\n",
    "valid_dir = \"../Repos/image-inpainting/dataset/test\"\n",
    "\n",
    "NUM_WORKERS = 2\n",
    "BS = 2\n",
    "LR = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class ImageInpaintingSystem(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ImageInpaintingSystem, self).__init__()\n",
    "        self.pConvUNet = PConvUNet()\n",
    "        \n",
    "        vgg16extractor = VGG16Extractor().to(\"cuda\")\n",
    "        for param in vgg16extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.lossCompute = LossCompute(vgg16extractor)\n",
    "        \n",
    "        self.preprocess = Preprocessor(\"cuda\")\n",
    "\n",
    "    def forward(self, masked_img_tensor, mask_tensor):\n",
    "        return self.pConvUNet(masked_img_tensor, mask_tensor)\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        masked_img, mask, image  = batch\n",
    "        \n",
    "        img_tensor = self.preprocess.normalize(image.type(torch.float))\n",
    "        mask_tensor = mask.type(torch.float).transpose(1, 3)\n",
    "        masked_img_tensor = self.preprocess.normalize(masked_img.type(torch.float))\n",
    "        \n",
    "        ls_fn = self.lossCompute.loss_total(mask_tensor)\n",
    "        output = self.forward(masked_img_tensor, mask_tensor)\n",
    "        loss = ls_fn(img_tensor, output).mean()\n",
    "        \n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        masked_img, mask, image  = batch\n",
    "        \n",
    "        img_tensor = self.preprocess.normalize(image.type(torch.float))\n",
    "        mask_tensor = mask.type(torch.float).transpose(1, 3)\n",
    "        masked_img_tensor = self.preprocess.normalize(masked_img.type(torch.float))\n",
    "        \n",
    "        ls_fn = self.lossCompute.loss_total(mask_tensor)\n",
    "        output = self.forward(masked_img_tensor, mask_tensor)\n",
    "        loss = ls_fn(img_tensor, output)\n",
    "        \n",
    "        psnr = self.lossCompute.PSNR(img_tensor, output)\n",
    "\n",
    "        res = np.clip(self.preprocess.unnormalize(output).detach().cpu().numpy(),0,1)\n",
    "        original_img = np.clip(self.preprocess.unnormalize(masked_img_tensor).detach().cpu().numpy(),0,1)\n",
    "        combined_img = np.concatenate((original_img[0], res[0]))\n",
    "        self.logger.experiment.add_image('images', combined_img, dataformats='HWC')   \n",
    "        return {'val_loss': loss, 'psnr': psnr}\n",
    "    \n",
    "    def validation_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_psnr = torch.stack([x['psnr'] for x in outputs]).mean()\n",
    "        tqdm_dict = {'valid_psnr': avg_psnr, 'valid_loss': avg_loss}\n",
    "        return {'log':tqdm_dict,'valid_loss': avg_loss, 'valid_psnr': avg_psnr}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=LR)\n",
    "\n",
    "    @pl.data_loader\n",
    "    def train_dataloader(self):\n",
    "        mask_generator = MaskGenerator(mask_dir, HEIGHT,WIDTH, invert_mask=invert_mask) \n",
    "        dataset = ImagesDataset(train_dir, HEIGHT, WIDTH, mask_generator)\n",
    "        dataloader = DataLoader(dataset, batch_size=BS, shuffle=True, num_workers=NUM_WORKERS)\n",
    "        return dataloader\n",
    "    \n",
    "    @pl.data_loader\n",
    "    def val_dataloader(self):\n",
    "        mask_generator = MaskGenerator(mask_dir, HEIGHT,WIDTH, invert_mask=invert_mask) \n",
    "        dataset = ImagesDataset(valid_dir, HEIGHT, WIDTH, mask_generator)\n",
    "        dataloader = DataLoader(dataset, batch_size=BS, shuffle=False, num_workers=NUM_WORKERS)\n",
    "        return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu available: True, used: True\n",
      "VISIBLE GPUS: 0\n",
      "55116 masks found: ../Repos/image-inpainting/dataset/irregular_mask/irregular_mask/disocclusion_img_mask/\n",
      "55116 masks found: ../Repos/image-inpainting/dataset/irregular_mask/irregular_mask/disocclusion_img_mask/\n",
      "                             Name           Type Params\n",
      "0                       pConvUNet      PConvUNet   32 M\n",
      "1              pConvUNet.encoder1   PConvEncoder    9 K\n",
      "2        pConvUNet.encoder1.pconv  PartialConv2d    9 K\n",
      "3    pConvUNet.encoder1.batchnorm    BatchNorm2d  128  \n",
      "4   pConvUNet.encoder1.activation           ReLU    0  \n",
      "..                            ...            ...    ...\n",
      "78       pConvUNet.decoder8.pconv  PartialConv2d    1 K\n",
      "79   pConvUNet.decoder8.batchnorm    BatchNorm2d    6  \n",
      "80  pConvUNet.decoder8.activation      LeakyReLU    0  \n",
      "81            pConvUNet.convfinal         Conv2d   12  \n",
      "82              pConvUNet.sigmoid        Sigmoid    0  \n",
      "\n",
      "[83 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]D:\\Image-Inpainting\\loss\\loss_compute.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dilated_mask = torch.tensor(dilated_mask> 0, dtype=torch.float, requires_grad=False).to(self.device)\n",
      " 73%|███████▎  | 58/79 [00:19<00:05,  4.03it/s, batch_nb=56, epoch=43, gpu=0, loss=4.109, v_nb=4]"
     ]
    }
   ],
   "source": [
    "model = ImageInpaintingSystem()\n",
    "\n",
    "trainer = Trainer(gpus=1, train_percent_check=0.001, use_amp=False)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
